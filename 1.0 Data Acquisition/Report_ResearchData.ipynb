{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to produce table and figure for the Research Data section of the write-up.\n",
    "\n",
    "Data file downloaded from Datastream is SET100_Data.xlsx  \n",
    "\n",
    "See StockDatabase_Read om 2.0.\n",
    "\n",
    "\n",
    "Table 1. List of 160 stocks  \n",
    "Table 2. Description of historical data attributes  \n",
    "Table 3. Summary statistics of technical indicator values  \n",
    "Table 4. List of dates the SET100 index was updated and the constituent list published  \n",
    "Table 5. List of stocks added and removed at each index update.  \n",
    "Table 6. Description of stock tickers that no longer exist.  \n",
    "Table 7. Observation count of each stock time series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import init_experiment\n",
    "db_engine = init_experiment(EXPERIMENT_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common import packages\n",
    "from experiment import os, np, pd, pdr, plt, datetime\n",
    "import datetime as dt\n",
    "import xlrd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe of Companies\n",
    "\n",
    "The information about companies are in the first sheet. This is loaded into data frame and is inserted into table.\n",
    "\n",
    "The file SET100_Data.xlsm is the master list of all companies in the universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First sheet list all companies\n",
    "# VO sheet contains VO data\n",
    "\n",
    "# Row 3  LOC;  Row 4  Datatype  Row 5 Name\n",
    "os.chdir(os.environ['DATA_HOME'] + '/Datastream')\n",
    "\n",
    "sheets = pd.read_excel('SET100_Data.xlsm', sheet_name=[0,'VO','MV','P','MACD']) \n",
    "sheets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Dimension   set100_company_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ticker symbols\n",
    "symbols = list(sheets[0]['Symbol In SET100 Constituent'].values)\n",
    "\n",
    "# Data frame\n",
    "df_tickers = sheets[0][['Symbol In SET100 Constituent', 'Company Name', 'Datastream Mnemonic', 'Remark']]\n",
    "df_tickers # All 163 stock symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickers[df_tickers[\"Symbol In SET100 Constituent\"]==\"SIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 160 companies\n",
    "df_companies = df_tickers[df_tickers['Datastream Mnemonic'].notnull()]\n",
    "df_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Directory with Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SET100 companies with the sector\n",
    "sector_lookup = os.path.join(os.environ['EXPERIMENT_HOME'],\"\"\"1.0 Data Acquisition/stock_ticker.csv\"\"\")\n",
    "sector_lookup = pd.read_csv(sector_lookup)\n",
    "\n",
    "set100_companies = df_companies[['Symbol In SET100 Constituent', 'Company Name', 'Datastream Mnemonic']]\n",
    "set100_companies\n",
    "\n",
    "# Join\n",
    "df = set100_companies.merge(sector_lookup, left_on='Symbol In SET100 Constituent', right_on='symbol')\n",
    "df['localCode'] = 'TH:'+df['symbol']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.environ['DATA_HOME'] + \"/set100.data\")\n",
    "df.to_csv('_directory.csv') # overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Volume Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VO = sheets['VO']\n",
    "\n",
    "# Headers\n",
    "localCode = VO[2:3]  # Stock symbol. Subtract first three chars: \"TH:\"\n",
    "companyName = VO[4:5]  # Name\n",
    "bDate = VO[5:6] # dataAvailableFrom\n",
    "dbEntityCode = VO[6:7] # internal dataase code \n",
    "\n",
    "# Index column, use to index rows\n",
    "rowIdx = VO[7:]['Start'].rename('Date') # This is the date data colume. Name the column 'Date'\n",
    "\n",
    "# Data cells\n",
    "df_VO = VO[7:]   # Data\n",
    "\n",
    "# df_VO.columns = companyName.values[0] # Set local code as column header\n",
    "df_VO.columns = list(map(lambda n: n[3:],localCode.values[0])) # Convert local code to symbol and use as column header\n",
    "df_VO = df_VO.set_index(rowIdx) # Make index on date column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact.VO :  Measure=VO  Key=Company,Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot do pivot table in this structure.\n",
    "\n",
    "# Pivot table: Value=Sector; the number of data observations for the stock.\n",
    "# ptable = df.pivot_table(values='sector', index='symbol', columns=['industry', 'localCode'])\n",
    "# ptable.tail()\n",
    "\n",
    "# needs numeric value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table: Value=Observations; the number of data observations for the stock.\n",
    "# ptable = df.pivot_table(values='Observations', index='Date', columns=['Industry', 'Sector', 'Ticker'])\n",
    "# ptable.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations count at last date of the dataset.\n",
    "# table_7 = ptable['2019-12-31':].T\n",
    "# table_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_7.to_csv('table_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# table = df.pivot(columns='Ticker')['Observations'] # Pivot table\n",
    "# table\n",
    "\n",
    "# table_7.pivot()['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = os.path.join(os.environ['EXPERIMENT_HOME'],'tables','table_7')\n",
    "# table_7.to_csv(output)\n",
    "\n",
    "# table_7[['Ticker']].index\n",
    "# table_7.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get ticker from multiindex.\n",
    "# tickers = np.array([i[2] for i in table_7.index.values])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,18))\n",
    "table_7.plot.barh(ax=ax, legend=False) # , xticks=tickers to change ticker\n",
    "\n",
    "ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "ax.tick_params(axis='y', which='minor', labelsize=8)\n",
    "plt.xlabel('Observations Count (Closing Price)')\n",
    "plt.title(\"SET100 Stocks: Closing price observations during 2015-2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Database Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATA_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataset_db\n",
    "dataset_db=get_dataset_db()\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    name\n",
    "FROM \n",
    "    sqlite_master \n",
    "WHERE \n",
    "    type ='table' AND \n",
    "    name NOT LIKE 'sqlite_%';\n",
    "\"\"\"\n",
    "tables = pd.read_sql(sql, dataset_db)\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export\n",
    "\n",
    "Export: stockdb  \n",
    "https://github.com/chayapan/thesis/blob/master/dataset/stockdb.sql.gz\n",
    "\n",
    "To:  \n",
    "1. fourStock_OHLC.csv  and then overwrite fourStock_prices.csv\n",
    "2. allStocks_OHLC.csv  and then overwrite allStocks_prices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# engine = create_engine('postgresql://datauser:1234@172.18.0.1:5432/stockdb', echo=False)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://optjar:1nv3NT0ry@10.30.0.2:5432/stockdb', echo=False) # TODO: remove this information before commit to Git.\n",
    "\n",
    "dataset_db = engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price\n",
    "\n",
    "## Select 4 stocks\n",
    "\n",
    "sqlite table:  set100_daily_fact  \n",
    "postgreql table: set100_daily_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SQL for SQLite3\n",
    "sql = \"\"\"SELECT f.date, f.stock, f.\"P\" FROM set100_daily_facts f\n",
    "WHERE f.stock IN ('TH:SCB','TH:KBANK','TH:PTT','TH:TOP');\"\"\"\n",
    "\n",
    "\n",
    "# SQL for PostgreSQL\n",
    "sql = \"\"\"SELECT f.date, f.stock, f.\"P\" FROM set100_daily_facts f\n",
    "WHERE f.stock IN ('TH:SCB','TH:KBANK','TH:PTT','TH:TOP');\"\"\"\n",
    "df_fact = pd.read_sql(sql, dataset_db)\n",
    "df_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by date\n",
    "sql = \"\"\"SELECT f.date, f.stock, f.P FROM set100_daily_fact f\n",
    "-- AND f.stock IN ('TH:SCB','TH:KBANK','TH:PTT','TH:TOP')\n",
    ";\"\"\"\n",
    "df_fact = pd.read_sql(sql, dataset_db)\n",
    "df_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM set100_daily_fact;\n",
    "\"\"\"\n",
    "pd.read_sql(sql, dataset_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM set100_company_dim;\n",
    "\"\"\"\n",
    "dim_company = pd.read_sql(sql, dataset_db)\n",
    "dim_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM daily_price;\n",
    "\"\"\"\n",
    "pd.read_sql(sql, dataset_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM set100_time_dim;\n",
    "\"\"\"\n",
    "pd.read_sql(sql, dataset_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data set\n",
    "\n",
    "joining time dimension with company dimention to fact\n",
    "\n",
    "index column  dayofyear  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT t.dayofyear, f.stock, f.P\n",
    "FROM \n",
    "set100_time_dim AS t \n",
    "JOIN\n",
    "set100_daily_fact AS f\n",
    "ON t.dt = f.date;\n",
    "\"\"\"\n",
    "pd.read_sql(sql, dataset_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = pd.read_csv(os.environ['DATA_HOME'] + '/Datastream/set100_daily_facts.csv.gz')\n",
    "fact.to_sql('daily_price', con=dataset_db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT c.symbol, f.stock, f.date, f.P price\n",
    "FROM \n",
    "set100_company_dim AS c \n",
    "JOIN\n",
    "daily_price AS f\n",
    "ON c.company_name = f.stock;\n",
    "\"\"\"\n",
    "df_price = pd.read_sql(sql, dataset_db)\n",
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price[['symbol', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(fact[['stock','MACD']], hue=\"stock\")\n",
    "\n",
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ('SCB','KBANK','PTT','TOP')\n",
    "\n",
    "series = []\n",
    "for s in stocks:\n",
    "    s1 = df_price[df_price['stock']==s][['date','price']]\n",
    "    s1 = s1.set_index('date').rename(columns={'price':s})\n",
    "    series.append(s1)\n",
    "df = pd.concat(series, axis=1) # Make data frame with each stock a column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price[df_price['stock'] == 'TOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_company[dim_company['symbol']=='KBANK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price[df_price['stock']=='KBANK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"set100_daily_facts\"  ## postgreSQL\n",
    "stock = \"\"\"'KASI%'\"\"\"\n",
    "\n",
    "table = \"daily_price\"  ## sqlite3\n",
    "stock = \"\"\"'TH:KB%'\"\"\"\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM {table}\n",
    "WHERE stock LIKE {stock};\n",
    "\"\"\".format(table=table, stock=stock)\n",
    "\n",
    "print(sql)\n",
    "pd.read_sql(sql, dataset_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Each Stock Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get Unique Stock\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT(c.symbol) FROM set100_company_dim AS c;\n",
    "\"\"\"\n",
    "df_symbols = pd.read_sql(sql, dataset_db)\n",
    "df_symbols\n",
    "\n",
    "\n",
    "# 2. Each Stock\n",
    "\n",
    "def get_stock_price(symbol):\n",
    "    \"\"\"Required: dataset_db - the connection to database instance.\n",
    "        Returns pandas DataFrame. \"\"\"\n",
    "    table = \"\" # daily_price for sqlite3\n",
    "    table = \"set100_daily_facts\" # for postgresql\n",
    "    sql = \"\"\"\n",
    "    SELECT c.symbol, f.stock, f.date, f.\"P\" price\n",
    "    FROM \n",
    "    set100_company_dim AS c \n",
    "    JOIN\n",
    "    %s AS f\n",
    "    ON c.company_name = f.stock\n",
    "    WHERE c.symbol='%s';\n",
    "    \"\"\" % (table, symbol)\n",
    "    df_price = pd.read_sql(sql, dataset_db)\n",
    "    df_price = df_price.fillna(0) # handle missing value by filing with zero\n",
    "    return df_price[['date','price']].set_index('date').rename(columns={'price':symbol})\n",
    "\n",
    "s1 = get_stock_price('KBANK') # For sqlite3\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = get_stock_price('SCB')\n",
    "s2 = get_stock_price('KBANK')\n",
    "s3 = get_stock_price('TOP')\n",
    "s4 = get_stock_price('PTT')\n",
    "series = [s1, s2, s3, s4]\n",
    "\n",
    "s1.plot(ax=plt.gca())\n",
    "s2.plot(ax=plt.gca())\n",
    "s3.plot(ax=plt.gca())\n",
    "s4.plot(ax=plt.gca())\n",
    "plt.title('Sample four stocks')\n",
    "\n",
    "df1 = pd.concat(series, axis=1) # Make data frame with each stock a column\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('fourStock_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = list(df_symbols['symbol'].values)\n",
    "series = []\n",
    "for s in symbols:\n",
    "    p = get_stock_price(s)\n",
    "    if len(p) > 100: # CHECK\n",
    "        series.append(p)\n",
    "        \n",
    "    \n",
    "\n",
    "df2 = pd.concat(series, axis=1) # Make data frame with each stock a column\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in series:\n",
    "    try:\n",
    "        s.plot(ax=plt.gca())\n",
    "    except:\n",
    "        print(\"Error for %s \" % str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('allStocks_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(fact[['stock','P']], hue=\"stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price distribution of the stock dataset. Color denotes each stock."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
