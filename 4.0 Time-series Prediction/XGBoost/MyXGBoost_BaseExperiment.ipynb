{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Home:  /home/jovyan ; Data Home: /home/jovyan/dataset\n"
     ]
    }
   ],
   "source": [
    "import sys, os, os.path\n",
    "if not 'EXPERIMENT_HOME' in os.environ: # Configure local paths if not already defined\n",
    "    ML_HOME = os.path.abspath(os.path.join(\"..\", \"..\",\"ml_home\")) # ML workspace\n",
    "    EXPERIMENT_HOME = os.path.abspath(os.path.join(ML_HOME, \"..\")) # Experiment workspace\n",
    "    DATA_HOME = os.path.abspath(os.path.join(EXPERIMENT_HOME,\"dataset\")) # Dataset location\n",
    "    os.environ[\"EXPERIMENT_HOME\"] = EXPERIMENT_HOME\n",
    "    os.environ[\"DATA_HOME\"] = DATA_HOME\n",
    "    sys.path.insert(0, EXPERIMENT_HOME)\n",
    "    sys.path.insert(0, ML_HOME) # Add to path so can load our library\n",
    "    os.chdir(EXPERIMENT_HOME) # Change working directory to experiment workspace\n",
    "print(\"Experiment Home: \", os.path.abspath(os.curdir), \"; Data Home:\", DATA_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: AOT\n",
      "Loading: AP\n",
      "Loading: BTS\n",
      "Loading: CPF\n",
      "Loading: KBANK\n",
      "Loading: KSL\n",
      "Loading: LH\n",
      "Loading: PTT\n",
      "Loading: RATCH\n",
      "Loading: SCB\n",
      "Loading: SET\n",
      "Loading: SET100\n",
      "Loading: SET50\n"
     ]
    }
   ],
   "source": [
    "from data.pilot import load_pilot_series, list_pilot_series\n",
    "\n",
    "# list_pilot_series()\n",
    "dataset = load_pilot_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import os, os.path\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>price-0-day-ago</th>\n",
       "      <th>price-1-day-ago</th>\n",
       "      <th>price-2-day-ago</th>\n",
       "      <th>price-3-day-ago</th>\n",
       "      <th>price-4-day-ago</th>\n",
       "      <th>price-5-day-ago</th>\n",
       "      <th>price-6-day-ago</th>\n",
       "      <th>price-7-day-ago</th>\n",
       "      <th>price-8-day-ago</th>\n",
       "      <th>...</th>\n",
       "      <th>price-48-day-ago</th>\n",
       "      <th>price-49-day-ago</th>\n",
       "      <th>1-day-ahead</th>\n",
       "      <th>3-day-ahead</th>\n",
       "      <th>5-day-ahead</th>\n",
       "      <th>7-day-ahead</th>\n",
       "      <th>10-day-ahead</th>\n",
       "      <th>15-day-ahead</th>\n",
       "      <th>20-day-ahead</th>\n",
       "      <th>30-day-ahead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-08</th>\n",
       "      <td>1103.55</td>\n",
       "      <td>1103.55</td>\n",
       "      <td>1106.15</td>\n",
       "      <td>1093.50</td>\n",
       "      <td>1096.79</td>\n",
       "      <td>1092.58</td>\n",
       "      <td>1068.71</td>\n",
       "      <td>1073.26</td>\n",
       "      <td>1075.91</td>\n",
       "      <td>1066.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1096.47</td>\n",
       "      <td>1083.32</td>\n",
       "      <td>1092.69</td>\n",
       "      <td>1088.37</td>\n",
       "      <td>1081.78</td>\n",
       "      <td>1084.27</td>\n",
       "      <td>1077.51</td>\n",
       "      <td>1070.23</td>\n",
       "      <td>1047.02</td>\n",
       "      <td>1065.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11</th>\n",
       "      <td>1092.69</td>\n",
       "      <td>1092.69</td>\n",
       "      <td>1103.55</td>\n",
       "      <td>1106.15</td>\n",
       "      <td>1093.50</td>\n",
       "      <td>1096.79</td>\n",
       "      <td>1092.58</td>\n",
       "      <td>1068.71</td>\n",
       "      <td>1073.26</td>\n",
       "      <td>1075.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1095.04</td>\n",
       "      <td>1096.47</td>\n",
       "      <td>1095.68</td>\n",
       "      <td>1085.44</td>\n",
       "      <td>1085.81</td>\n",
       "      <td>1075.77</td>\n",
       "      <td>1089.67</td>\n",
       "      <td>1054.88</td>\n",
       "      <td>1048.85</td>\n",
       "      <td>1067.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12</th>\n",
       "      <td>1095.68</td>\n",
       "      <td>1095.68</td>\n",
       "      <td>1092.69</td>\n",
       "      <td>1103.55</td>\n",
       "      <td>1106.15</td>\n",
       "      <td>1093.50</td>\n",
       "      <td>1096.79</td>\n",
       "      <td>1092.58</td>\n",
       "      <td>1068.71</td>\n",
       "      <td>1073.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1085.80</td>\n",
       "      <td>1095.04</td>\n",
       "      <td>1088.37</td>\n",
       "      <td>1081.78</td>\n",
       "      <td>1084.27</td>\n",
       "      <td>1073.10</td>\n",
       "      <td>1083.70</td>\n",
       "      <td>1054.28</td>\n",
       "      <td>1057.87</td>\n",
       "      <td>1070.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13</th>\n",
       "      <td>1088.37</td>\n",
       "      <td>1088.37</td>\n",
       "      <td>1095.68</td>\n",
       "      <td>1092.69</td>\n",
       "      <td>1103.55</td>\n",
       "      <td>1106.15</td>\n",
       "      <td>1093.50</td>\n",
       "      <td>1096.79</td>\n",
       "      <td>1092.58</td>\n",
       "      <td>1068.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1099.93</td>\n",
       "      <td>1085.80</td>\n",
       "      <td>1085.44</td>\n",
       "      <td>1085.81</td>\n",
       "      <td>1075.77</td>\n",
       "      <td>1077.51</td>\n",
       "      <td>1084.13</td>\n",
       "      <td>1053.40</td>\n",
       "      <td>1066.63</td>\n",
       "      <td>1068.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14</th>\n",
       "      <td>1085.44</td>\n",
       "      <td>1085.44</td>\n",
       "      <td>1088.37</td>\n",
       "      <td>1095.68</td>\n",
       "      <td>1092.69</td>\n",
       "      <td>1103.55</td>\n",
       "      <td>1106.15</td>\n",
       "      <td>1093.50</td>\n",
       "      <td>1096.79</td>\n",
       "      <td>1092.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1108.91</td>\n",
       "      <td>1099.93</td>\n",
       "      <td>1081.78</td>\n",
       "      <td>1084.27</td>\n",
       "      <td>1073.10</td>\n",
       "      <td>1089.67</td>\n",
       "      <td>1077.30</td>\n",
       "      <td>1048.76</td>\n",
       "      <td>1048.08</td>\n",
       "      <td>1068.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close  price-0-day-ago  price-1-day-ago  price-2-day-ago  \\\n",
       "Date                                                                     \n",
       "2019-11-08  1103.55          1103.55          1106.15          1093.50   \n",
       "2019-11-11  1092.69          1092.69          1103.55          1106.15   \n",
       "2019-11-12  1095.68          1095.68          1092.69          1103.55   \n",
       "2019-11-13  1088.37          1088.37          1095.68          1092.69   \n",
       "2019-11-14  1085.44          1085.44          1088.37          1095.68   \n",
       "\n",
       "            price-3-day-ago  price-4-day-ago  price-5-day-ago  \\\n",
       "Date                                                            \n",
       "2019-11-08          1096.79          1092.58          1068.71   \n",
       "2019-11-11          1093.50          1096.79          1092.58   \n",
       "2019-11-12          1106.15          1093.50          1096.79   \n",
       "2019-11-13          1103.55          1106.15          1093.50   \n",
       "2019-11-14          1092.69          1103.55          1106.15   \n",
       "\n",
       "            price-6-day-ago  price-7-day-ago  price-8-day-ago  ...  \\\n",
       "Date                                                           ...   \n",
       "2019-11-08          1073.26          1075.91          1066.48  ...   \n",
       "2019-11-11          1068.71          1073.26          1075.91  ...   \n",
       "2019-11-12          1092.58          1068.71          1073.26  ...   \n",
       "2019-11-13          1096.79          1092.58          1068.71  ...   \n",
       "2019-11-14          1093.50          1096.79          1092.58  ...   \n",
       "\n",
       "            price-48-day-ago  price-49-day-ago  1-day-ahead  3-day-ahead  \\\n",
       "Date                                                                       \n",
       "2019-11-08           1096.47           1083.32      1092.69      1088.37   \n",
       "2019-11-11           1095.04           1096.47      1095.68      1085.44   \n",
       "2019-11-12           1085.80           1095.04      1088.37      1081.78   \n",
       "2019-11-13           1099.93           1085.80      1085.44      1085.81   \n",
       "2019-11-14           1108.91           1099.93      1081.78      1084.27   \n",
       "\n",
       "            5-day-ahead  7-day-ahead  10-day-ahead  15-day-ahead  \\\n",
       "Date                                                               \n",
       "2019-11-08      1081.78      1084.27       1077.51       1070.23   \n",
       "2019-11-11      1085.81      1075.77       1089.67       1054.88   \n",
       "2019-11-12      1084.27      1073.10       1083.70       1054.28   \n",
       "2019-11-13      1075.77      1077.51       1084.13       1053.40   \n",
       "2019-11-14      1073.10      1089.67       1077.30       1048.76   \n",
       "\n",
       "            20-day-ahead  30-day-ahead  \n",
       "Date                                    \n",
       "2019-11-08       1047.02       1065.23  \n",
       "2019-11-11       1048.85       1067.99  \n",
       "2019-11-12       1057.87       1070.74  \n",
       "2019-11-13       1066.63       1068.72  \n",
       "2019-11-14       1048.08       1068.50  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data series and clean-up missing values\n",
    "def prep_series_for_XGBoost(df, window=50):\n",
    "    data = df\n",
    "    # Target: Tomorrow's closing price\n",
    "    data.loc[:,(\"Tomorrow\")] = data[\"Price\"].shift(-1)\n",
    "    # data.dropna(inplace=True)\n",
    "\n",
    "    # Past: Historical data\n",
    "    features = []\n",
    "    for i in range(window):\n",
    "        f_col = \"price-%s-day-ago\" % i\n",
    "        data.loc[:,(f_col)] = data[\"Close\"].shift(i)\n",
    "        features.append(f_col)\n",
    "\n",
    "    # Target: Future time\n",
    "    targets = []\n",
    "    for t in [1,3,5,7,10,15,20,30]:\n",
    "        t_col = \"%s-day-ahead\" % t\n",
    "        data.loc[:,(t_col)] = data[\"Close\"].shift(-t)\n",
    "        targets.append(t_col)\n",
    "\n",
    "    # Initial Setup XGBoost.\n",
    "    # Run with 5 TI: SMA WMA ADOSC ATR RSI\n",
    "    # Only use Closing price\n",
    "    # df = data[['Price','1-day-ahead']]\n",
    "    df = data[['Close'] + features + targets]\n",
    "    return df, features, targets\n",
    "\n",
    "df_series, features, targets = prep_series_for_XGBoost(dataset['SET50'], window=50)\n",
    "df_series.dropna(inplace=True) # Remove NA row\n",
    "df_series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Data partition')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_series\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "train_df['Close'].plot(ax=ax)\n",
    "val_df['Close'].plot(ax=ax)\n",
    "test_df['Close'].plot(ax=ax)\n",
    "ax.legend(['Train', 'Validate', 'Test'])\n",
    "plt.title(\"Data partition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>price-0-day-ago</th>\n",
       "      <th>price-1-day-ago</th>\n",
       "      <th>price-2-day-ago</th>\n",
       "      <th>price-3-day-ago</th>\n",
       "      <th>price-4-day-ago</th>\n",
       "      <th>price-5-day-ago</th>\n",
       "      <th>price-6-day-ago</th>\n",
       "      <th>price-7-day-ago</th>\n",
       "      <th>price-8-day-ago</th>\n",
       "      <th>...</th>\n",
       "      <th>price-48-day-ago</th>\n",
       "      <th>price-49-day-ago</th>\n",
       "      <th>1-day-ahead</th>\n",
       "      <th>3-day-ahead</th>\n",
       "      <th>5-day-ahead</th>\n",
       "      <th>7-day-ahead</th>\n",
       "      <th>10-day-ahead</th>\n",
       "      <th>15-day-ahead</th>\n",
       "      <th>20-day-ahead</th>\n",
       "      <th>30-day-ahead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-16</th>\n",
       "      <td>996.39</td>\n",
       "      <td>996.39</td>\n",
       "      <td>1012.25</td>\n",
       "      <td>1013.98</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>1027.02</td>\n",
       "      <td>1032.49</td>\n",
       "      <td>1022.09</td>\n",
       "      <td>1027.89</td>\n",
       "      <td>...</td>\n",
       "      <td>980.50</td>\n",
       "      <td>987.40</td>\n",
       "      <td>997.43</td>\n",
       "      <td>1012.18</td>\n",
       "      <td>1006.03</td>\n",
       "      <td>1002.56</td>\n",
       "      <td>993.27</td>\n",
       "      <td>1027.62</td>\n",
       "      <td>1039.53</td>\n",
       "      <td>1003.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-17</th>\n",
       "      <td>997.43</td>\n",
       "      <td>997.43</td>\n",
       "      <td>996.39</td>\n",
       "      <td>1012.25</td>\n",
       "      <td>1013.98</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>1027.02</td>\n",
       "      <td>1032.49</td>\n",
       "      <td>1022.09</td>\n",
       "      <td>...</td>\n",
       "      <td>998.05</td>\n",
       "      <td>980.50</td>\n",
       "      <td>1010.99</td>\n",
       "      <td>1010.67</td>\n",
       "      <td>1005.12</td>\n",
       "      <td>992.82</td>\n",
       "      <td>997.66</td>\n",
       "      <td>1023.97</td>\n",
       "      <td>1033.75</td>\n",
       "      <td>990.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>1010.99</td>\n",
       "      <td>1010.99</td>\n",
       "      <td>997.43</td>\n",
       "      <td>996.39</td>\n",
       "      <td>1012.25</td>\n",
       "      <td>1013.98</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>1027.02</td>\n",
       "      <td>1032.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.24</td>\n",
       "      <td>998.05</td>\n",
       "      <td>1012.18</td>\n",
       "      <td>1006.03</td>\n",
       "      <td>1002.56</td>\n",
       "      <td>993.33</td>\n",
       "      <td>1010.04</td>\n",
       "      <td>1023.65</td>\n",
       "      <td>1040.23</td>\n",
       "      <td>1001.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-19</th>\n",
       "      <td>1012.18</td>\n",
       "      <td>1012.18</td>\n",
       "      <td>1010.99</td>\n",
       "      <td>997.43</td>\n",
       "      <td>996.39</td>\n",
       "      <td>1012.25</td>\n",
       "      <td>1013.98</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>1027.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.87</td>\n",
       "      <td>1013.24</td>\n",
       "      <td>1010.67</td>\n",
       "      <td>1005.12</td>\n",
       "      <td>992.82</td>\n",
       "      <td>993.27</td>\n",
       "      <td>1015.30</td>\n",
       "      <td>1025.38</td>\n",
       "      <td>1024.61</td>\n",
       "      <td>996.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-20</th>\n",
       "      <td>1010.67</td>\n",
       "      <td>1010.67</td>\n",
       "      <td>1012.18</td>\n",
       "      <td>1010.99</td>\n",
       "      <td>997.43</td>\n",
       "      <td>996.39</td>\n",
       "      <td>1012.25</td>\n",
       "      <td>1013.98</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1019.38</td>\n",
       "      <td>1017.87</td>\n",
       "      <td>1006.03</td>\n",
       "      <td>1002.56</td>\n",
       "      <td>993.33</td>\n",
       "      <td>997.66</td>\n",
       "      <td>1017.08</td>\n",
       "      <td>1043.73</td>\n",
       "      <td>1019.38</td>\n",
       "      <td>986.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-15</th>\n",
       "      <td>1117.85</td>\n",
       "      <td>1117.85</td>\n",
       "      <td>1121.70</td>\n",
       "      <td>1128.55</td>\n",
       "      <td>1135.11</td>\n",
       "      <td>1131.83</td>\n",
       "      <td>1130.91</td>\n",
       "      <td>1141.12</td>\n",
       "      <td>1145.95</td>\n",
       "      <td>1141.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1165.17</td>\n",
       "      <td>1175.24</td>\n",
       "      <td>1100.25</td>\n",
       "      <td>1090.62</td>\n",
       "      <td>1071.18</td>\n",
       "      <td>1065.20</td>\n",
       "      <td>1051.63</td>\n",
       "      <td>1063.71</td>\n",
       "      <td>1080.05</td>\n",
       "      <td>1127.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18</th>\n",
       "      <td>1100.25</td>\n",
       "      <td>1100.25</td>\n",
       "      <td>1117.85</td>\n",
       "      <td>1121.70</td>\n",
       "      <td>1128.55</td>\n",
       "      <td>1135.11</td>\n",
       "      <td>1131.83</td>\n",
       "      <td>1130.91</td>\n",
       "      <td>1141.12</td>\n",
       "      <td>1145.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1136.72</td>\n",
       "      <td>1165.17</td>\n",
       "      <td>1071.96</td>\n",
       "      <td>1068.68</td>\n",
       "      <td>1061.68</td>\n",
       "      <td>1060.58</td>\n",
       "      <td>1058.12</td>\n",
       "      <td>1069.83</td>\n",
       "      <td>1069.04</td>\n",
       "      <td>1143.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-19</th>\n",
       "      <td>1071.96</td>\n",
       "      <td>1071.96</td>\n",
       "      <td>1100.25</td>\n",
       "      <td>1117.85</td>\n",
       "      <td>1121.70</td>\n",
       "      <td>1128.55</td>\n",
       "      <td>1135.11</td>\n",
       "      <td>1131.83</td>\n",
       "      <td>1130.91</td>\n",
       "      <td>1141.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1147.21</td>\n",
       "      <td>1136.72</td>\n",
       "      <td>1090.62</td>\n",
       "      <td>1071.18</td>\n",
       "      <td>1065.20</td>\n",
       "      <td>1050.60</td>\n",
       "      <td>1069.77</td>\n",
       "      <td>1085.36</td>\n",
       "      <td>1068.09</td>\n",
       "      <td>1132.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-20</th>\n",
       "      <td>1090.62</td>\n",
       "      <td>1090.62</td>\n",
       "      <td>1071.96</td>\n",
       "      <td>1100.25</td>\n",
       "      <td>1117.85</td>\n",
       "      <td>1121.70</td>\n",
       "      <td>1128.55</td>\n",
       "      <td>1135.11</td>\n",
       "      <td>1131.83</td>\n",
       "      <td>1130.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1159.00</td>\n",
       "      <td>1147.21</td>\n",
       "      <td>1068.68</td>\n",
       "      <td>1061.68</td>\n",
       "      <td>1060.58</td>\n",
       "      <td>1051.63</td>\n",
       "      <td>1073.20</td>\n",
       "      <td>1078.82</td>\n",
       "      <td>1077.22</td>\n",
       "      <td>1133.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-21</th>\n",
       "      <td>1068.68</td>\n",
       "      <td>1068.68</td>\n",
       "      <td>1090.62</td>\n",
       "      <td>1071.96</td>\n",
       "      <td>1100.25</td>\n",
       "      <td>1117.85</td>\n",
       "      <td>1121.70</td>\n",
       "      <td>1128.55</td>\n",
       "      <td>1135.11</td>\n",
       "      <td>1131.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1164.71</td>\n",
       "      <td>1159.00</td>\n",
       "      <td>1071.18</td>\n",
       "      <td>1065.20</td>\n",
       "      <td>1050.60</td>\n",
       "      <td>1058.12</td>\n",
       "      <td>1054.84</td>\n",
       "      <td>1079.87</td>\n",
       "      <td>1084.85</td>\n",
       "      <td>1122.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close  price-0-day-ago  price-1-day-ago  price-2-day-ago  \\\n",
       "Date                                                                     \n",
       "2015-03-16   996.39           996.39          1012.25          1013.98   \n",
       "2015-03-17   997.43           997.43           996.39          1012.25   \n",
       "2015-03-18  1010.99          1010.99           997.43           996.39   \n",
       "2015-03-19  1012.18          1012.18          1010.99           997.43   \n",
       "2015-03-20  1010.67          1010.67          1012.18          1010.99   \n",
       "...             ...              ...              ...              ...   \n",
       "2018-06-15  1117.85          1117.85          1121.70          1128.55   \n",
       "2018-06-18  1100.25          1100.25          1117.85          1121.70   \n",
       "2018-06-19  1071.96          1071.96          1100.25          1117.85   \n",
       "2018-06-20  1090.62          1090.62          1071.96          1100.25   \n",
       "2018-06-21  1068.68          1068.68          1090.62          1071.96   \n",
       "\n",
       "            price-3-day-ago  price-4-day-ago  price-5-day-ago  \\\n",
       "Date                                                            \n",
       "2015-03-16          1015.94          1005.25          1027.02   \n",
       "2015-03-17          1013.98          1015.94          1005.25   \n",
       "2015-03-18          1012.25          1013.98          1015.94   \n",
       "2015-03-19           996.39          1012.25          1013.98   \n",
       "2015-03-20           997.43           996.39          1012.25   \n",
       "...                     ...              ...              ...   \n",
       "2018-06-15          1135.11          1131.83          1130.91   \n",
       "2018-06-18          1128.55          1135.11          1131.83   \n",
       "2018-06-19          1121.70          1128.55          1135.11   \n",
       "2018-06-20          1117.85          1121.70          1128.55   \n",
       "2018-06-21          1100.25          1117.85          1121.70   \n",
       "\n",
       "            price-6-day-ago  price-7-day-ago  price-8-day-ago  ...  \\\n",
       "Date                                                           ...   \n",
       "2015-03-16          1032.49          1022.09          1027.89  ...   \n",
       "2015-03-17          1027.02          1032.49          1022.09  ...   \n",
       "2015-03-18          1005.25          1027.02          1032.49  ...   \n",
       "2015-03-19          1015.94          1005.25          1027.02  ...   \n",
       "2015-03-20          1013.98          1015.94          1005.25  ...   \n",
       "...                     ...              ...              ...  ...   \n",
       "2018-06-15          1141.12          1145.95          1141.39  ...   \n",
       "2018-06-18          1130.91          1141.12          1145.95  ...   \n",
       "2018-06-19          1131.83          1130.91          1141.12  ...   \n",
       "2018-06-20          1135.11          1131.83          1130.91  ...   \n",
       "2018-06-21          1128.55          1135.11          1131.83  ...   \n",
       "\n",
       "            price-48-day-ago  price-49-day-ago  1-day-ahead  3-day-ahead  \\\n",
       "Date                                                                       \n",
       "2015-03-16            980.50            987.40       997.43      1012.18   \n",
       "2015-03-17            998.05            980.50      1010.99      1010.67   \n",
       "2015-03-18           1013.24            998.05      1012.18      1006.03   \n",
       "2015-03-19           1017.87           1013.24      1010.67      1005.12   \n",
       "2015-03-20           1019.38           1017.87      1006.03      1002.56   \n",
       "...                      ...               ...          ...          ...   \n",
       "2018-06-15           1165.17           1175.24      1100.25      1090.62   \n",
       "2018-06-18           1136.72           1165.17      1071.96      1068.68   \n",
       "2018-06-19           1147.21           1136.72      1090.62      1071.18   \n",
       "2018-06-20           1159.00           1147.21      1068.68      1061.68   \n",
       "2018-06-21           1164.71           1159.00      1071.18      1065.20   \n",
       "\n",
       "            5-day-ahead  7-day-ahead  10-day-ahead  15-day-ahead  \\\n",
       "Date                                                               \n",
       "2015-03-16      1006.03      1002.56        993.27       1027.62   \n",
       "2015-03-17      1005.12       992.82        997.66       1023.97   \n",
       "2015-03-18      1002.56       993.33       1010.04       1023.65   \n",
       "2015-03-19       992.82       993.27       1015.30       1025.38   \n",
       "2015-03-20       993.33       997.66       1017.08       1043.73   \n",
       "...                 ...          ...           ...           ...   \n",
       "2018-06-15      1071.18      1065.20       1051.63       1063.71   \n",
       "2018-06-18      1061.68      1060.58       1058.12       1069.83   \n",
       "2018-06-19      1065.20      1050.60       1069.77       1085.36   \n",
       "2018-06-20      1060.58      1051.63       1073.20       1078.82   \n",
       "2018-06-21      1050.60      1058.12       1054.84       1079.87   \n",
       "\n",
       "            20-day-ahead  30-day-ahead  \n",
       "Date                                    \n",
       "2015-03-16       1039.53       1003.19  \n",
       "2015-03-17       1033.75        990.69  \n",
       "2015-03-18       1040.23       1001.04  \n",
       "2015-03-19       1024.61        996.27  \n",
       "2015-03-20       1019.38        986.51  \n",
       "...                  ...           ...  \n",
       "2018-06-15       1080.05       1127.56  \n",
       "2018-06-18       1069.04       1143.46  \n",
       "2018-06-19       1068.09       1132.47  \n",
       "2018-06-20       1077.22       1133.78  \n",
       "2018-06-21       1084.85       1122.94  \n",
       "\n",
       "[798 rows x 59 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df[features]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    # Suppress warning: https://www.dataquest.io/blog/settingwithcopywarning/\n",
    "    train_df[features] = sc.fit_transform(train_df[features])\n",
    "    val_df[features] = sc.transform(val_df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((798, 50), (798, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df[features].values  # .values so becomes numpy array to feed to model. Ex. diabetes = datasets.load_diabetes()\n",
    "y = train_df[['1-day-ahead']].values    # Check that dimension and type same as example dataset: diabetes.data, diabetes.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[features].values\n",
    "y_train = train_df[['1-day-ahead']].values\n",
    "\n",
    "X_test = val_df[features].values\n",
    "y_test = val_df[['1-day-ahead']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 133.7156\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, reg.predict(X_train))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 206.0441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 5,\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'ls'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 10,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, reg.predict(X_train))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "\n",
    "params # Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 140.1989\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 5,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, reg.predict(X_train))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 3, 5, 7, 10, 15, 20, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 133.0530\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 208.2103\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 139.6062\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 132.9665\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 209.0063\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 140.1858\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 133.6817\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 208.2067\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 141.6114\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 132.8031\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 204.5048\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 141.4862\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 134.5973\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 208.2473\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 140.1577\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 133.7526\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 209.0933\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 141.4050\n",
      "Forecast: %s-day ahead\n",
      "Parameter Set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 23.4393\n",
      "The mean squared error (MSE) on test set: 134.3678\n",
      "Parameter Set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.0001\n",
      "The mean squared error (MSE) on test set: 208.8344\n",
      "Parameter Set: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 4.4640\n",
      "The mean squared error (MSE) on test set: 140.4479\n"
     ]
    }
   ],
   "source": [
    "params_set = {}\n",
    "\n",
    "params_set[1] = {'n_estimators': 500,\n",
    "              'max_depth': 4,\n",
    "              'min_samples_split': 5,\n",
    "              'learning_rate': 0.01,\n",
    "              'loss': 'ls'}\n",
    "params_set[2] = {'n_estimators': 1000,\n",
    "              'max_depth': 10,\n",
    "              'min_samples_split': 5,\n",
    "              'learning_rate': 0.01,\n",
    "              'loss': 'ls'}\n",
    "params_set[3] = {'n_estimators': 1000,\n",
    "              'max_depth': 5,\n",
    "              'min_samples_split': 5,\n",
    "              'learning_rate': 0.01,\n",
    "              'loss': 'ls'}\n",
    "\n",
    "models = []\n",
    "\n",
    "for fh in 3, 5, 7, 10, 15, 20, 30:\n",
    "    print(\"Forecast: %s-day ahead\" % fh)\n",
    "    for k, params in params_set.items():\n",
    "        print(\"Parameter Set: %s\" % k)\n",
    "        reg = ensemble.GradientBoostingRegressor(**params)\n",
    "        \n",
    "        X_train = train_df[features].values\n",
    "        y_train = train_df[['%s-day-ahead' % fh]].values\n",
    "\n",
    "        X_test = val_df[features].values\n",
    "        y_test = val_df[['%s-day-ahead' % fh]].values\n",
    "        \n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_train, reg.predict(X_train))\n",
    "        print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "\n",
    "        mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "        print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
