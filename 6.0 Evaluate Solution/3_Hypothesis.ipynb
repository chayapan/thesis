{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Forecast\n",
    "\n",
    "The forecast model when created had hypothesis produced and the parameter is fitted by the initial data available when the forecast instance was created.\n",
    "\n",
    "To combine two forecast models, we can use semantic that a combined instance is created from individual forecast models.\n",
    "\n",
    "So we defined the combined class that contain one or more forecast model (the fitted hypothesis).\n",
    "\n",
    "\n",
    "Previously we defined TimeSeriesCluster class and ForecastModel class that perform their functions.\n",
    "\n",
    "\n",
    "The GroupForecast instance can share individual data points from its individual members. This need to ensure the data is standardized so that it make sense to combine them.\n",
    "\n",
    "\n",
    "For combining data points, use MinMaxScaler to normalize the data.\n",
    "\n",
    "\n",
    "Specification:\n",
    "\n",
    "1. MSE  \n",
    "2. 80/20 train/test split  \n",
    "3. MinMax scaler  \n",
    "4. more complex data path for simulation, like a rotated sine wave or superposition of two basis paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Data access class \n",
    "class TimeSeriesDataset:\n",
    "    \"\"\"\n",
    "        - All time series share the same timeline.\"\"\"\n",
    "    def __init__(self, lookback='3m', lookahead='7d'):\n",
    "        if lookback=='3m':\n",
    "            lookback = 60\n",
    "        if lookahead=='7d':\n",
    "            lookahead = 7\n",
    "        # TODO: make lookback and lookahead argument support more shorthand notations.\n",
    "        self.lookback = lookback\n",
    "        self.lookahead = lookahead\n",
    "        # TODO: need semantic for t.\n",
    "        t = np.arange(0,100)\n",
    "        self.t = t # the main timeline.\n",
    "    @property\n",
    "    def timeline(self):\n",
    "        \"\"\"The main timeline. Used for the clustering. This timeline is shared among all time series.\"\"\"\n",
    "        return self.t\n",
    "    @property\n",
    "    def series(self):\n",
    "        \"\"\"Time-series data as list. For clustering.\"\"\"\n",
    "        items = []\n",
    "        for k, s in self.series_itemset.items():\n",
    "            items.append[s]\n",
    "        return items\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"Item labels. For clustering.\"\"\"\n",
    "        labels = []\n",
    "        for k, s in self.series_itemset.items():\n",
    "            labels.append[k]\n",
    "        return labels\n",
    "    @property\n",
    "    def series_itemset(self):\n",
    "        \"\"\"The item set of series.\"\"\"\n",
    "        return []\n",
    "        \n",
    "    def get_series(self, series_id):\n",
    "        \"\"\"Get data series by ID. All series share same timeline. Use lookback/lookahead to set up a time line.\"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "# Two classes from 2_Forecasting.ipynb are defined in condensed form here: TimeSeriesCluster and ForecastModel\n",
    "class TimeSeriesCluster:\n",
    "    \"\"\"Main class for time-series clustering. See original for reference.\"\"\"\n",
    "    def __init__(self, timeline, series, labels):\n",
    "        \"\"\"Receive timeline, time-series items, and object labels.\n",
    "            Ex.\n",
    "            timeline = np.arange(100)\n",
    "            labels = ['y1', 'y2', 'y3', 'y4']\n",
    "            items = [y1, y2, y3, y4]\n",
    "        \"\"\"\n",
    "        # choose distance function\n",
    "        d_func = self.dtw_dist_ret\n",
    "        self.items = series # map series to a list of item. Define series as argument as the list of individual series.\n",
    "        self.labels = labels # object labels\n",
    "        self.D = pdist(self.items, d_func) # compute distance table\n",
    "        self.Z = linkage(self.D, method='single')\n",
    "        self.k = 2\n",
    "        # clusters # the output labels\n",
    "        self.clusters = fcluster(self.Z, self.k, criterion='maxclust')\n",
    "    @classmethod\n",
    "    def dtw_dist_ret(cls, u, v):\n",
    "        # use FastDTW (approximation of DTW) to measure dissimarity. This generally works on price series.\n",
    "        # If series received is returns series, use cumsum() to reconstruct price series.\n",
    "        # \n",
    "        # If want to explore further transformation, try: compute_daily_returns and my_dtw_dist\n",
    "        return fastdtw(u,v)[0]\n",
    "\n",
    "class ForecastModel:\n",
    "    \"\"\"This is a template forecast model.\"\"\"\n",
    "    def __init__(self, timeline, data):\n",
    "        \"\"\"timeline is shared among all models. data is unique to each model.\n",
    "        - Main accuracy metric is MSE.\n",
    "        - Validation set is the last 20% of the data.\n",
    "        - data argument is the training/validation data we can use to fit the model.\n",
    "        \n",
    "        - y_prime is the output of the make_hypothesis mockup.\n",
    "        - y_hat is the hypothesis to be tested in the hold-out data.\n",
    "        \"\"\"\n",
    "        self.t = timeline.astype(np.int)\n",
    "        self.y = data\n",
    "        y_prime, slope, intercept = self.make_hypothesis(data, timeline)\n",
    "        self.y_hat = y_prime.reshape((self.y.size,)) # make data same dimension\n",
    "        self.slope = slope[0] # keep just the first coefficient. Note that for multivariate regression this will be vectors\n",
    "        self.intercept = intercept\n",
    "        self.errors = self.fitting_errors()\n",
    "        self.avg_error = np.average(self.errors)\n",
    "    def make_hypothesis(self, data, t):\n",
    "        \"\"\"Returns a linear forecast model.\"\"\"\n",
    "        # data is np.array of values of quantities observed in each time step.\n",
    "        t, v = t[:, np.newaxis], data  # Newaxis trick follow the example in statsmodel linear regression tutorial\n",
    "        # Create linear regression object\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(t, v) # find slope and intercept\n",
    "        # Our model H is y = m * x + c\n",
    "        # - m is the slope which is the coefficient\n",
    "        # - c is the bias or in this case the first data point (left-most value).\n",
    "        m = regr.coef_\n",
    "        c = v[0]\n",
    "        y_hat = m * t + c  # this is the model for linear forecast.  it will be subject to IID error.\n",
    "        return y_hat, m, c\n",
    "    def fitting_errors(self):\n",
    "        return np.abs(self.y - self.y_hat).sum()\n",
    "    def forecast(self, y_train, horizon=60):\n",
    "        \"\"\"Stores data in t_forecast variable and y_forecast variable. return the portion of the forecast.\n",
    "        \n",
    "        To make forecast.\n",
    "        \"\"\"\n",
    "        steps = horizon # time steps to forecast\n",
    "        # use linear model to make forecast.\n",
    "        # Returns forecast values.\n",
    "        # last value becomes the intercept c.\n",
    "        last_value = y_train[-1]  # TODO: consider change the name of y to y train\n",
    "        c = self.intercept # use the intercept from fitting stage!\n",
    "        # needing y_train as input feels wired. But without this we can get confused if the self.y has future data or not.\n",
    "        # the t here is the steps\n",
    "        # t = steps to step into the future\n",
    "        m = self.slope # slope comes from the hypothesis already fitted.        \n",
    "        # time-index for the forecasted period\n",
    "        self.t_forecast = np.arange(60) + self.t[-1] + 1   # The first value is the horizon. Is is a bug?\n",
    "        \n",
    "        # y_hat = m * t + c    \n",
    "        self.y_forecast = m * self.t_forecast + c\n",
    "        return self.y_forecast\n",
    "    def __repr__(self):\n",
    "        avg_err = self.avg_error\n",
    "        return \"\"\"LinearModel slope=%s intercept=%s error=%s\"\"\" % (self.slope, self.intercept, avg_err)\n",
    "\n",
    "\n",
    "class ForecastAsGroup:\n",
    "    \"\"\"ForecastAsGroup combines individual forecast model and make forecast as a group.\"\"\"\n",
    "    def __init__(self, models=[]):\n",
    "        self.avg_error = 0.0\n",
    "        for m in models:\n",
    "            assert isinstance(m, ForecastModel) # Model or type ForecastModel\n",
    "            self.avg_error += m.avg_error # Add individual average error. See individual model.\n",
    "        self.models = models \n",
    "    def __repr__(self):\n",
    "        avg_err = self.avg_error\n",
    "        return \"\"\"GroupForecastModel error=%s n=%s\"\"\" % (avg_err, len(self.models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupForecastModel error=3270.8040955849647 n=4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(0,100)\n",
    "iid_noise = lambda : np.random.normal(0,5,x.size)\n",
    "m_std = 0.1\n",
    "\n",
    "def time_series_data_type1(m, c, m_std = 0.1):\n",
    "    m = m + np.random.normal(0,m_std,100)\n",
    "    c = c + iid_noise()\n",
    "    y = m * x + c\n",
    "    return y\n",
    "dgf_1 = time_series_data_type1\n",
    "y1 = dgf_1(m=5, c=100)\n",
    "y2 = dgf_1(m=5, c=130)\n",
    "y3 = dgf_1(m=1, c=50)\n",
    "y4 = dgf_1(m=1, c=75)\n",
    "fm1 = ForecastModel(x, y1)\n",
    "fm2 = ForecastModel(x, y2)\n",
    "fm3 = ForecastModel(x, y3)\n",
    "fm4 = ForecastModel(x, y4)\n",
    "\n",
    "gf1 = ForecastAsGroup([fm1, fm2, fm3, fm4])\n",
    "gf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast with 80/20 split\n",
    "\n",
    "Because we're using 80/20 split for the forecast model. Due to linear ordering of the time sequence. It is common to use forward chaining to set up the partition between training and validation data. This mean use the first 80% of the data for training the model, then using the remaining 20% of the data as validation set. This validation set is used for optimizing the model's hyperparameters. \n",
    "\n",
    "To choose the hyperparameter during the model tuning process we use training set and validation set to calibrate the model. This means adjusting parameters using training set and observing improvement or degradation of the model-in-training. We can exhaustively search the solution space for optimal parameter combination using this setting. (Of course this naive approch needs a good heuristic guide to be successful.)\n",
    "\n",
    "In this section we simply develop generic class implementation for this step.\n",
    "\n",
    "Where to place the MSE calculation method?\n",
    "\n",
    "\n",
    "Where to do the 80/20 split?\n",
    "\n",
    "\n",
    "What is the procedure for doing the standardization/normalization and inverse the procedure? Describe step by step where this happen and when the transform back occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
