{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Need to set up tests in tests/\n",
    "\n",
    "pytest.main([\"-q\"])\n",
    "\n",
    "https://pytest.org/en/stable/usage.html\n",
    "\n",
    "\n",
    "Recommend project layout.\n",
    "https://blog.ionelmc.ro/2014/05/25/python-packaging/#the-structure\n",
    "\n",
    "\n",
    "Write tests.\n",
    "https://docs.pytest.org/en/latest/getting-started.html\n",
    "\n",
    "See notes at.\n",
    "https://redmine.corp.disqrete.com/projects/technology-stack/wiki/PyTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....                                                                    [100%]\n",
      "=============================== warnings summary ===============================\n",
      "test_modules.py::test_local_stockdata\n",
      "  /opt/workspace/ml_home/data/src.py:80: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "  of pandas will change to not sort by default.\n",
      "  \n",
      "  To accept the future behavior, pass 'sort=False'.\n",
      "  \n",
      "  To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "  \n",
      "    df = pd.concat(rows, ignore_index=True)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "5 passed, 1 warning in 3.14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest\n",
    "pytest.main([\"-q\", \"test_modules.py\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# content of test_sample.py\n",
    "def func(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def test_answer():\n",
    "    assert func(3) == 5\n",
    "\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def error_fixture():\n",
    "    assert 0\n",
    "\n",
    "\n",
    "def test_ok():\n",
    "    print(\"ok\")\n",
    "\n",
    "\n",
    "def test_fail():\n",
    "    assert 0\n",
    "\n",
    "\n",
    "def test_error(error_fixture):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_skip():\n",
    "    pytest.skip(\"skipping this test\")\n",
    "\n",
    "\n",
    "def test_xfail():\n",
    "    pytest.xfail(\"xfailing this test\")\n",
    "\n",
    "\n",
    "@pytest.mark.xfail(reason=\"always xfail\")\n",
    "def test_xpass():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.clustering import dendrogram_with_extra_info \n",
    "assert callable(dendrogram_with_extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.src import to_float, read_csv_from_historical_folder, stockdata_fetch_local\n",
    "from data.src import indexdata_fetch_local, stockdata_fetch_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.simulation import TimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.simulation import make_dataset_linear, make_dataset_exponential\n",
    "from data.generator import make_gbm_series, dgf10, dgf11\n",
    "# The simulation data generating function rely on data generator module.\n",
    "\n",
    "## TODO: create test suite for simulation\n",
    "pytest.main([\"-q\", \"test_hypothesis_sim.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".F.                                                                      [100%]\n",
      "=================================== FAILURES ===================================\n",
      "___________________________ test_set100_company_dim ____________________________\n",
      "\n",
      "    def test_set100_company_dim():\n",
      "        \"\"\"The company dimension table should contain 160 companies. There are 163 symbols and 3 were duplicates.\"\"\"\n",
      "        from experiment import os, np, pd\n",
      "        os.chdir(os.environ['DATA_HOME'] + '/Datastream')\n",
      "    \n",
      "        sheets = pd.read_excel('SET100_Data.xlsm', sheet_name=[0])\n",
      "    \n",
      "        # List of ticker symbols\n",
      "        symbols = list(sheets[0]['Symbol In SET100 Constituent'].values)\n",
      "    \n",
      "        # Data frame\n",
      "        df_tickers = sheets[0][['Symbol In SET100 Constituent', 'Company Name', 'Datastream Mnemonic', 'Remark']]\n",
      "        df_tickers # All 163 stock symbols\n",
      "    \n",
      "        # The 160 companies\n",
      "        df_companies = df_tickers[df_tickers['Datastream Mnemonic'].notnull()]\n",
      "        df_companies\n",
      "    \n",
      "        # The SET100 companies with the sector\n",
      "        sector_lookup = os.path.join(os.environ['EXPERIMENT_HOME'],\"\"\"1.0 Data Acquisition/stock_ticker.csv\"\"\")\n",
      ">       sector_lookup = pd.read_csv(sector_lookup)\n",
      "\n",
      "/opt/workspace/tests/test_data_warehouse.py:47: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:685: in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:457: in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:895: in __init__\n",
      "    self._make_engine(self.engine)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:1135: in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:1917: in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "pandas/_libs/parsers.pyx:382: in pandas._libs.parsers.TextReader.__cinit__\n",
      "    ???\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ">   ???\n",
      "E   FileNotFoundError: [Errno 2] File b'/opt/workspace/dataset/1.0 Data Acquisition/stock_ticker.csv' does not exist: b'/opt/workspace/dataset/1.0 Data Acquisition/stock_ticker.csv'\n",
      "\n",
      "pandas/_libs/parsers.pyx:689: FileNotFoundError\n",
      "=============================== warnings summary ===============================\n",
      "test_data_warehouse.py::test_load_universe_of_companies\n",
      "test_data_warehouse.py::test_load_universe_of_companies\n",
      "test_data_warehouse.py::test_set100_company_dim\n",
      "test_data_warehouse.py::test_set100_company_dim\n",
      "  /opt/conda/lib/python3.7/site-packages/xlrd/xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "    for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "\n",
      "test_data_warehouse.py::test_load_universe_of_companies\n",
      "test_data_warehouse.py::test_set100_company_dim\n",
      "  /opt/conda/lib/python3.7/site-packages/xlrd/xlsx.py:312: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "    for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_data_warehouse.py::test_set100_company_dim - FileNotFoundError: [...\n",
      "1 failed, 2 passed, 6 warnings in 126.79s (0:02:06)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell can be execute independently from other cells in this notebook.\n",
    "\n",
    "import pytest\n",
    "pytest.main([\"-q\", \"test_data_warehouse.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
